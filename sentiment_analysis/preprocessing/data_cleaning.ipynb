{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/namirsacic/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/namirsacic/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from path import Path\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file):\n",
    "    file_path = Path(csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for english tweets\n",
    "def filter_tweets(df):\n",
    "    df = df[df.lang == \"en\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows that donÂ´t contain tweets\n",
    "def drop_rows(df): \n",
    "    index_names = df[ df['created_at'] == \"created_at\" ].index\n",
    "  \n",
    "    # drop these row indexes\n",
    "    # from dataFrame\n",
    "    df.drop(index_names, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns = [\"created_at\", \"tweet\"]\n",
    "\n",
    "def get_series_of_tweets(df):\n",
    "    \n",
    "    df = df[needed_columns]\n",
    "    df.created_at = pd.to_datetime(df.created_at).dt.date\n",
    "    tweets = df[\"tweet\"]\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following function removes URLs, punctuation, stopwords and converts text into lowercase\n",
    "def clean_tweets(tweets):\n",
    "    #Removing URLs from tweets\n",
    "    remove_url = lambda x: re.sub(r'https\\S+', '', str(x))\n",
    "    tweets_lr = tweets.apply(remove_url)\n",
    "    tweets_lr\n",
    "    \n",
    "    #Convert to lowercase\n",
    "    to_lower = lambda x: x.lower()\n",
    "    tweets_lr_lc = tweets_lr.apply(to_lower)\n",
    "    tweets_lr_lc\n",
    "    \n",
    "    #Removing punctuation\n",
    "    remove_puncs = lambda x: x.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    tweets_lr_lc_np = tweets_lr_lc.apply(remove_puncs)\n",
    "    tweets_lr_lc_np\n",
    "    \n",
    "    #Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"English\"))\n",
    "\n",
    "    remove_words = lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
    "    tweets_lr_lc_np_ns = tweets_lr_lc_np.apply(remove_words)\n",
    "    \n",
    "    return tweets_lr_lc_np_ns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(df, tweets, csv_name):\n",
    "    df.tweet = tweets\n",
    "    df.to_csv(csv_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namirsacic/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (0,3,5,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "aapl_df = csv_to_df(\"../tweets/aapl_tweets.csv\")\n",
    "btc_df = csv_to_df(\"../tweets/btc_tweets.csv\")\n",
    "jnj_df = csv_to_df(\"../tweets/jnj_tweets.csv\")\n",
    "msft_df = csv_to_df(\"../tweets/msft_tweets.csv\")\n",
    "nflx_df = csv_to_df(\"../tweets/nflx_tweets.csv\")\n",
    "pfe_df = csv_to_df(\"../tweets/pfe_tweets.csv\")\n",
    "tsla_df = csv_to_df(\"../tweets/tsla_tweets.csv\")\n",
    "twr_df = csv_to_df(\"../tweets/twr_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop non-english tweets\n",
    "aapl_df = filter_tweets(aapl_df)\n",
    "btc_df = filter_tweets(btc_df)\n",
    "jnj_df = filter_tweets(jnj_df)\n",
    "msft_df = filter_tweets(msft_df)\n",
    "nflx_df = filter_tweets(nflx_df)\n",
    "pfe_df = filter_tweets(pfe_df)\n",
    "tsla_df = filter_tweets(tsla_df)\n",
    "twr_df = filter_tweets(twr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_df = drop_rows(aapl_df)\n",
    "btc_df = drop_rows(btc_df)\n",
    "jnj_df = drop_rows(jnj_df)\n",
    "msft_df = drop_rows(msft_df)\n",
    "nflx_df = drop_rows(nflx_df)\n",
    "pfe_df = drop_rows(pfe_df)\n",
    "tsla_df = drop_rows(tsla_df)\n",
    "twr_df = drop_rows(twr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namirsacic/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "aapl_tweets = get_series_of_tweets(aapl_df)\n",
    "btc_tweets = get_series_of_tweets(btc_df)\n",
    "jnj_tweets = get_series_of_tweets(jnj_df)\n",
    "msft_tweets = get_series_of_tweets(msft_df)\n",
    "nflx_tweets = get_series_of_tweets(nflx_df)\n",
    "pfe_tweets = get_series_of_tweets(pfe_df)\n",
    "tsla_tweets = get_series_of_tweets(tsla_df)\n",
    "twr_tweets = get_series_of_tweets(twr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_tweets = clean_tweets(aapl_tweets)\n",
    "btc_tweets = clean_tweets(btc_tweets)\n",
    "jnj_tweets = clean_tweets(jnj_tweets)\n",
    "msft_tweets = clean_tweets(msft_tweets)\n",
    "nflx_tweets = clean_tweets(nflx_tweets)\n",
    "pfe_tweets = clean_tweets(pfe_tweets)\n",
    "tsla_tweets = clean_tweets(tsla_tweets)\n",
    "twr_tweets = clean_tweets(twr_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(aapl_df, aapl_tweets, \"aapl_cleaned.csv\")\n",
    "create_csv(btc_df, btc_tweets, \"btc_cleaned.csv\")\n",
    "create_csv(jnj_df, jnj_tweets, \"jnj_cleaned.csv\")\n",
    "create_csv(msft_df, msft_tweets, \"msft_cleaned.csv\")\n",
    "create_csv(nflx_df, nflx_tweets, \"nflx_cleaned.csv\")\n",
    "create_csv(pfe_df, pfe_tweets, \"pfe_cleaned.csv\")\n",
    "create_csv(tsla_df, tsla_tweets, \"tsla_cleaned.csv\")\n",
    "create_csv(twr_df, twr_tweets, \"twr_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
